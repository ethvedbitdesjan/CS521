{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vqa import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900200090 20009\n",
      "900200220 20022\n",
      "900200280 20028\n",
      "900200340 20034\n",
      "900200380 20038\n",
      "900200450 20045\n",
      "900200470 20047\n",
      "900200500 20050\n",
      "900200520 20052\n",
      "900200540 20054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img_dir = r\"C:\\Users\\ved67\\UIUC\\CS521\\CS521_HWs\\hw5\\VQA_Train\\scene_img_abstract_v002_train2017\"\n",
    "train_img_prefix = \"abstract_v002_train2015_\"\n",
    "train_question_json = r\"C:\\Users\\ved67\\UIUC\\CS521\\CS521_HWs\\hw5\\VQA_Train\\OpenEnded_abstract_v002_train2017_questions.json\"\n",
    "train_answer_json = r\"C:\\Users\\ved67\\UIUC\\CS521\\CS521_HWs\\hw5\\VQA_Train\\abstract_v002_train2017_annotations.json\"\n",
    "\n",
    "valid_img_dir = r\"C:\\Users\\ved67\\UIUC\\CS521\\CS521_HWs\\hw5\\VQA_Valid\\scene_img_abstract_v002_val2017\"\n",
    "valid_img_prefix = \"abstract_v002_val2015_\"\n",
    "valid_question_json = r\"C:\\Users\\ved67\\UIUC\\CS521\\CS521_HWs\\hw5\\VQA_Valid\\OpenEnded_abstract_v002_val2017_questions.json\"\n",
    "valid_answer_json = r\"C:\\Users\\ved67\\UIUC\\CS521\\CS521_HWs\\hw5\\VQA_Valid\\abstract_v002_val2017_annotations.json\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224))\n",
    "])\n",
    "tokenizer = SimpleTokenizer(max_len=50)\n",
    "valid_dataset = VQADataset(valid_img_dir, valid_img_prefix, valid_question_json, valid_answer_json, transform, tokenizer)\n",
    "complementary_pairs = []\n",
    "for img_id in valid_dataset.img_ids:\n",
    "    if len(str(img_id)) < 9:\n",
    "        complementary_id = int(\"900\"+str(img_id)+\"0\")\n",
    "        if complementary_id in valid_dataset.img_ids:\n",
    "            img1_data = {}\n",
    "            img2_data = {}\n",
    "            image, question_tokens, answer_tokens = valid_dataset[valid_dataset.img_ids.index(img_id)]\n",
    "            img1_data[\"image\"] = image\n",
    "            img1_data[\"question_tokens\"] = question_tokens\n",
    "            img1_data[\"answer_tokens\"] = answer_tokens\n",
    "            image, question_tokens, answer_tokens = valid_dataset[valid_dataset.img_ids.index(complementary_id)]\n",
    "            img2_data[\"image\"] = image\n",
    "            img2_data[\"question_tokens\"] = question_tokens\n",
    "            img2_data[\"answer_tokens\"] = answer_tokens\n",
    "            if str(img1_data[\"question_tokens\"].tolist()) != str(img2_data[\"question_tokens\"].tolist()):\n",
    "                continue\n",
    "            if len(tokenizer.decode(img1_data['question_tokens'])) > 40:\n",
    "                continue\n",
    "            print(complementary_id, img_id)\n",
    "            # print(img1_data[\"question_tokens\"], img2_data[\"question_tokens\"])\n",
    "            # print(\"cont\")\n",
    "            # print(img1_data[\"answer_tokens\"], img2_data[\"answer_tokens\"])\n",
    "            # print(\"end\")\n",
    "            complementary_pairs.append((img1_data, img2_data))\n",
    "    if len(complementary_pairs) >= 10:\n",
    "        break\n",
    "len(complementary_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"API_KEY\"] = 'API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "model_name = 'gemini-1.5-flash'\n",
    "genai.configure(api_key=os.environ[\"API_KEY\"])\n",
    "model = genai.GenerativeModel(model_name)\n",
    "\n",
    "def vqa(model, prompt, image):\n",
    "    response = model.generate_content([prompt, image])\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Given the image and the question, answer the question.\n",
    "\n",
    "The answer should be in the format:\n",
    "\n",
    "Explanation: <the explanation of the answer>\n",
    "#Answer: <yes/no>\n",
    "\n",
    "query: {question}\n",
    "\"\"\"\n",
    "\n",
    "def check_answer(model_answer, answer):\n",
    "    model_answer = model_answer.strip().split('#Answer:')[1].lower().strip()\n",
    "    if 'n' in model_answer and 'n' in answer:\n",
    "        return True, model_answer\n",
    "    elif 'y' in model_answer and 'y' in answer:\n",
    "        return True, model_answer\n",
    "    else:\n",
    "        assert model_answer == 'no' or model_answer == 'yes', f\"Invalid model answer: {model_answer}\"\n",
    "        return False, model_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def image_vqa(model, img_data):\n",
    "    vqa_data = {}\n",
    "    image, question_tokens, answer_tokens = img_data['image'], img_data['question_tokens'], img_data['answer_tokens']\n",
    "    question = tokenizer.decode(question_tokens)\n",
    "    answer = tokenizer.decode(answer_tokens)\n",
    "    prompt = prompt_template.format(question=question)\n",
    "    model_answer = vqa(model, prompt, image)\n",
    "    evaluation, shortened_answer = check_answer(model_answer, answer)\n",
    "    vqa_data['question'] = question\n",
    "    vqa_data['answer'] = answer\n",
    "    vqa_data['model_answer'] = model_answer\n",
    "    vqa_data['evaluation'] = evaluation\n",
    "    vqa_data['shortened_answer'] = shortened_answer\n",
    "    vqa_data['image'] = image\n",
    "    return vqa_data\n",
    "\n",
    "model_performance_data = {}\n",
    "for i in range(10):\n",
    "    img1_data, img2_data = complementary_pairs[i]\n",
    "    image, question_tokens, answer_tokens = valid_dataset[i]\n",
    "    question = tokenizer.decode(question_tokens)\n",
    "    \n",
    "    model_performance_data[i] = (image_vqa(model, img1_data), image_vqa(model, img2_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_pairs(img1_data, img2_data):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    ax[0].imshow(np.array(img1_data['image']))\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title('Image 1')\n",
    "    ax[1].imshow(np.array(img2_data['image']))\n",
    "    ax[1].axis('off')\n",
    "    ax[1].set_title('Image 2')\n",
    "    plt.suptitle(f'Question: {img1_data[\"question\"]}')\n",
    "    print(f'Image 1 answer: {img1_data[\"answer\"]}, {img1_data[\"shortened_answer\"]}')\n",
    "    print(f'Image 2 answer: {img2_data[\"answer\"]}, {img2_data[\"shortened_answer\"]}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal accuracy: 0.6\n",
      "Pair accuracy: 0.4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>answer1</th>\n",
       "      <th>model_answer1</th>\n",
       "      <th>evaluation1</th>\n",
       "      <th>shortened_answer1</th>\n",
       "      <th>question2</th>\n",
       "      <th>answer2</th>\n",
       "      <th>model_answer2</th>\n",
       "      <th>evaluation2</th>\n",
       "      <th>shortened_answer2</th>\n",
       "      <th>evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is the young boy in love with the dog?</td>\n",
       "      <td>yes</td>\n",
       "      <td>Explanation: The image shows a young boy sitti...</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "      <td>is the young boy in love with the dog?</td>\n",
       "      <td>no</td>\n",
       "      <td>Explanation:The image shows a young boy in a s...</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is he camping?</td>\n",
       "      <td>yes</td>\n",
       "      <td>Explanation:The image shows a man sitting on l...</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "      <td>is he camping?</td>\n",
       "      <td>no</td>\n",
       "      <td>Explanation:The image shows a man carrying log...</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is the girl lonely?</td>\n",
       "      <td>yes</td>\n",
       "      <td>Explanation: The image shows a girl sitting on...</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "      <td>is the girl lonely?</td>\n",
       "      <td>no</td>\n",
       "      <td>Explanation: The image shows a girl standing n...</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is he happy?</td>\n",
       "      <td>yes</td>\n",
       "      <td>Explanation: The image shows a boy playing on ...</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "      <td>is he happy?</td>\n",
       "      <td>yes</td>\n",
       "      <td>Explanation: The image shows a boy actively pl...</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>are there clouds in the sky?</td>\n",
       "      <td>no</td>\n",
       "      <td>Explanation:The image shows a clear sky with a...</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "      <td>are there clouds in the sky?</td>\n",
       "      <td>yes</td>\n",
       "      <td>Explanation:The image shows a single, small cl...</td>\n",
       "      <td>True</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                question1 answer1  \\\n",
       "0  is the young boy in love with the dog?     yes   \n",
       "1                          is he camping?     yes   \n",
       "2                     is the girl lonely?     yes   \n",
       "3                            is he happy?     yes   \n",
       "4            are there clouds in the sky?      no   \n",
       "\n",
       "                                       model_answer1  evaluation1  \\\n",
       "0  Explanation: The image shows a young boy sitti...        False   \n",
       "1  Explanation:The image shows a man sitting on l...         True   \n",
       "2  Explanation: The image shows a girl sitting on...        False   \n",
       "3  Explanation: The image shows a boy playing on ...         True   \n",
       "4  Explanation:The image shows a clear sky with a...         True   \n",
       "\n",
       "  shortened_answer1                               question2 answer2  \\\n",
       "0                no  is the young boy in love with the dog?      no   \n",
       "1               yes                          is he camping?      no   \n",
       "2                no                     is the girl lonely?      no   \n",
       "3               yes                            is he happy?     yes   \n",
       "4                no            are there clouds in the sky?     yes   \n",
       "\n",
       "                                       model_answer2  evaluation2  \\\n",
       "0  Explanation:The image shows a young boy in a s...         True   \n",
       "1  Explanation:The image shows a man carrying log...         True   \n",
       "2  Explanation: The image shows a girl standing n...         True   \n",
       "3  Explanation: The image shows a boy actively pl...         True   \n",
       "4  Explanation:The image shows a single, small cl...         True   \n",
       "\n",
       "  shortened_answer2  evaluation  \n",
       "0                no       False  \n",
       "1                no        True  \n",
       "2                no       False  \n",
       "3               yes        True  \n",
       "4               yes        True  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_performance_data = {}\n",
    "normal_correct = 0\n",
    "normal_total = 0\n",
    "pair_correct = 0\n",
    "for i, (img1_data, img2_data) in model_performance_data.items():\n",
    "    pair_performance_data[i] = {}\n",
    "    pair_performance_data[i]['question1'] = img1_data['question']\n",
    "    pair_performance_data[i]['answer1'] = img1_data['answer']\n",
    "    pair_performance_data[i]['model_answer1'] = img1_data['model_answer']\n",
    "    pair_performance_data[i]['evaluation1'] = img1_data['evaluation']\n",
    "    pair_performance_data[i]['shortened_answer1'] = img1_data['shortened_answer']\n",
    "    pair_performance_data[i]['question2'] = img2_data['question']\n",
    "    pair_performance_data[i]['answer2'] = img2_data['answer']\n",
    "    pair_performance_data[i]['model_answer2'] = img2_data['model_answer']\n",
    "    pair_performance_data[i]['evaluation2'] = img2_data['evaluation']\n",
    "    pair_performance_data[i]['shortened_answer2'] = img2_data['shortened_answer']\n",
    "    pair_performance_data[i]['evaluation'] = img1_data['evaluation'] and img2_data['evaluation']\n",
    "    normal_correct += img1_data['evaluation']\n",
    "    normal_total += 1\n",
    "    normal_correct += img2_data['evaluation']\n",
    "    normal_total += 1\n",
    "    pair_correct += img1_data['evaluation'] and img2_data['evaluation']\n",
    "\n",
    "print(f\"Normal accuracy: {normal_correct/normal_total}\")\n",
    "print(f\"Pair accuracy: {pair_correct/(normal_total//2)}\")\n",
    "\n",
    "pair_performance_df = pd.DataFrame.from_dict(pair_performance_data, orient='index')\n",
    "pair_performance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_performance_df.to_excel('model_performance.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
